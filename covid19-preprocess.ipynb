{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Visualization Project\n",
    "### COSC3000: Visualization, Computer Graphics & Data Analytics\n",
    "#### William Kvaale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wget\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the freshest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv',\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(urls):\n",
    "    dataset = [file for file in glob(\"dataset/*.csv\")]\n",
    "    N = len(dataset)\n",
    "    loaded = False if N == 3 else True\n",
    "    if not loaded:        \n",
    "        for url in urls:\n",
    "            print(f\"Downloading csv from {url} ...\")\n",
    "            wget.download(url, out=\"dataset\")\n",
    "    print(f\"The dataset contains {N}CSV-files:\")\n",
    "    print(*dataset, sep='\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The dataset contains 4CSV-files:\ndataset/time_series_covid19_confirmed_global.csv\ndataset/time_series_covid19_recovered_global.csv\ndataset/time_series_covid19_deaths_global.csv\ndataset/cases_country.csv\n"
    }
   ],
   "source": [
    "download_data(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_19_CONFIRMED = \"dataset/time_series_covid19_confirmed_global.csv\"\n",
    "COVID_19_RECOVERED = \"dataset/time_series_covid19_recovered_global.csv\"\n",
    "COVID_19_DEATHS = \"dataset/time_series_covid19_deaths_global.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CSV files into Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df = load_data(COVID_19_CONFIRMED)\n",
    "recovered_df = load_data(COVID_19_RECOVERED)\n",
    "deaths_df = load_data(COVID_19_DEATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20',\n       '1/24/20', '1/25/20', '1/26/20', '1/27/20',\n       ...\n       '4/18/20', '4/19/20', '4/20/20', '4/21/20', '4/22/20', '4/23/20',\n       '4/24/20', '4/25/20', '4/26/20', '4/27/20'],\n      dtype='object', length=101)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "confirmed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = confirmed_df.columns[4:]\n",
    "\n",
    "\n",
    "confirmed_latlong_df = confirmed_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "    value_vars=dates_df,\n",
    "    var_name='Date',\n",
    "    value_name='Confirmed'\n",
    ")\n",
    "\n",
    "recovered_latlong_df = recovered_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "    value_vars=dates_df,\n",
    "    var_name='Date',\n",
    "    value_name='Recovered'\n",
    ")\n",
    "\n",
    "deaths_latlong_df = deaths_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "    value_vars=dates_df,\n",
    "    var_name='Date',\n",
    "    value_name='Deaths'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " recovered_latlong_df = recovered_latlong_df[recovered_latlong_df['Country/Region']!='Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_df = confirmed_latlong_df.merge(\n",
    "    right=recovered_latlong_df,\n",
    "    how='left',\n",
    "    on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n",
    ")\n",
    "\n",
    "giant_df = giant_df.merge(\n",
    "    right=deaths_latlong_df,\n",
    "    how='left',\n",
    "    on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  Province/State         Country/Region        Lat       Long  \\\n0      NaN                        Afghanistan            33.000000  65.000000   \n1      NaN                        Albania                41.153300  20.168300   \n2      NaN                        Algeria                28.033900  1.659600    \n3      NaN                        Andorra                42.506300  1.521800    \n4      NaN                        Angola                -11.202700  17.873900   \n...    ...                           ...                       ...        ...   \n25603  Saint Pierre and Miquelon  France                 46.885200 -56.315900   \n25604  NaN                        South Sudan            6.877000   31.307000   \n25605  NaN                        Western Sahara         24.215500 -12.885800   \n25606  NaN                        Sao Tome and Principe  0.186360   6.613081    \n25607  NaN                        Yemen                  15.552727  48.516388   \n\n          Date  Confirmed  Recovered  Deaths  \n0      1/22/20  0          0.0        0       \n1      1/22/20  0          0.0        0       \n2      1/22/20  0          0.0        0       \n3      1/22/20  0          0.0        0       \n4      1/22/20  0          0.0        0       \n...        ... ..          ...       ..       \n25603  4/27/20  1          0.0        0       \n25604  4/27/20  6         NaN         0       \n25605  4/27/20  6          5.0        0       \n25606  4/27/20  4          0.0        0       \n25607  4/27/20  1         NaN         0       \n\n[25608 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Recovered</th>\n      <th>Deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>33.000000</td>\n      <td>65.000000</td>\n      <td>1/22/20</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>Albania</td>\n      <td>41.153300</td>\n      <td>20.168300</td>\n      <td>1/22/20</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Algeria</td>\n      <td>28.033900</td>\n      <td>1.659600</td>\n      <td>1/22/20</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>Andorra</td>\n      <td>42.506300</td>\n      <td>1.521800</td>\n      <td>1/22/20</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Angola</td>\n      <td>-11.202700</td>\n      <td>17.873900</td>\n      <td>1/22/20</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25603</th>\n      <td>Saint Pierre and Miquelon</td>\n      <td>France</td>\n      <td>46.885200</td>\n      <td>-56.315900</td>\n      <td>4/27/20</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25604</th>\n      <td>NaN</td>\n      <td>South Sudan</td>\n      <td>6.877000</td>\n      <td>31.307000</td>\n      <td>4/27/20</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25605</th>\n      <td>NaN</td>\n      <td>Western Sahara</td>\n      <td>24.215500</td>\n      <td>-12.885800</td>\n      <td>4/27/20</td>\n      <td>6</td>\n      <td>5.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25606</th>\n      <td>NaN</td>\n      <td>Sao Tome and Principe</td>\n      <td>0.186360</td>\n      <td>6.613081</td>\n      <td>4/27/20</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25607</th>\n      <td>NaN</td>\n      <td>Yemen</td>\n      <td>15.552727</td>\n      <td>48.516388</td>\n      <td>4/27/20</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25608 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "giant_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and clean the data\n",
    "- Convert date from string to DateTime\n",
    "- Check NaN values\n",
    "- Remove Cruise ships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_df['Date'] = pd.to_datetime(giant_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Province/State    17654\nCountry/Region    0    \nLat               0    \nLong              0    \nDate              0    \nConfirmed         0    \nRecovered         2716 \nDeaths            0    \ndtype: int64"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "giant_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some countries report their data only by country, instead of state for state, so this makes sense.\n",
    "The recovered set to NaN we will replace with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_df['Recovered'] = giant_df['Recovered'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cruise_ships_df = giant_df['Province/State'].str.contains('Grand Priness') | giant_df['Province/State'].str.contains('Diamond Priness') | giant_df['Country/Region'].str.contains('Diamon Priness') | giant_df['Country/Region'].str.contains('MS Zaandam')\n",
    "\n",
    "complete_cruise_ships_df = giant_df[~cruise_ships_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_df['Active'] = giant_df['Confirmed'] - giant_df['Recovered'] - giant_df['Deaths'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_grouped_df = giant_df.groupby(['Date', 'Country/Region'])['Confirmed', 'Recovered', 'Deaths', 'Active'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the indices is completely off, so we'll need to reset back to Date & Country/Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_grouped_df = giant_grouped_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns to be placeholders for daily new updates\n",
    "- New Cases\n",
    "- New Recovered\n",
    "- New Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_df = giant_grouped_df.groupby(['Country/Region', 'Date', ])['Confirmed', 'Recovered', 'Deaths']\n",
    "temporary_df = temporary_df.sum().diff().reset_index()\n",
    "\n",
    "masked_df = temporary_df['Country/Region'] != temporary_df['Country/Region'].shift(1)\n",
    "\n",
    "temporary_df.loc[masked_df, 'Confirmed'] = np.nan\n",
    "temporary_df.loc[masked_df, 'Recovered'] = np.nan\n",
    "temporary_df.loc[masked_df, 'Deaths'] = np.nan\n",
    "\n",
    "temporary_df.columns = ['Country/Region', 'Date', 'New Cases', 'New Recovered', 'New Deaths']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have prepared the temporary new values to be merged into the complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_grouped_df = pd.merge(giant_grouped_df, temporary_df, on=['Country/Region', 'Date'])\n",
    "\n",
    "giant_grouped_df = giant_grouped_df.fillna(0)\n",
    "\n",
    "giant_grouped_df[['New Cases', 'New Deaths', 'New Recovered']] = giant_grouped_df[['New Cases', 'New Recovered', 'New Deaths']].astype('int')\n",
    "\n",
    "giant_grouped_df['New Cases'] = giant_grouped_df['New Cases'].apply(lambda c: 0 if c < 0 else c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename UK\n",
    "giant_grouped_df['Country/Region'] = giant_grouped_df['Country/Region'].replace('United Kingdom', 'UK')\n",
    "\n",
    "# Rename Country/Region to Country\n",
    "giant_grouped_df.rename(columns={'Country/Region':'Country'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Date Country  Confirmed  Recovered  Deaths    Active  New Cases  \\\n17931 2020-04-27  US      988197     111424.0   56259   820514.0  22412       \n17746 2020-04-26  US      965785     106988.0   54881   803916.0  27631       \n17561 2020-04-25  US      938154     100372.0   53755   784027.0  32796       \n17376 2020-04-24  US      905358     99079.0    51949   754330.0  36188       \n17191 2020-04-23  US      869170     80203.0    49954   739013.0  28819       \n\n       New Recovered  New Deaths  \n17931  1378           4436        \n17746  1126           6616        \n17561  1806           1293        \n17376  1995           18876       \n17191  3332           2837        ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Country</th>\n      <th>Confirmed</th>\n      <th>Recovered</th>\n      <th>Deaths</th>\n      <th>Active</th>\n      <th>New Cases</th>\n      <th>New Recovered</th>\n      <th>New Deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17931</th>\n      <td>2020-04-27</td>\n      <td>US</td>\n      <td>988197</td>\n      <td>111424.0</td>\n      <td>56259</td>\n      <td>820514.0</td>\n      <td>22412</td>\n      <td>1378</td>\n      <td>4436</td>\n    </tr>\n    <tr>\n      <th>17746</th>\n      <td>2020-04-26</td>\n      <td>US</td>\n      <td>965785</td>\n      <td>106988.0</td>\n      <td>54881</td>\n      <td>803916.0</td>\n      <td>27631</td>\n      <td>1126</td>\n      <td>6616</td>\n    </tr>\n    <tr>\n      <th>17561</th>\n      <td>2020-04-25</td>\n      <td>US</td>\n      <td>938154</td>\n      <td>100372.0</td>\n      <td>53755</td>\n      <td>784027.0</td>\n      <td>32796</td>\n      <td>1806</td>\n      <td>1293</td>\n    </tr>\n    <tr>\n      <th>17376</th>\n      <td>2020-04-24</td>\n      <td>US</td>\n      <td>905358</td>\n      <td>99079.0</td>\n      <td>51949</td>\n      <td>754330.0</td>\n      <td>36188</td>\n      <td>1995</td>\n      <td>18876</td>\n    </tr>\n    <tr>\n      <th>17191</th>\n      <td>2020-04-23</td>\n      <td>US</td>\n      <td>869170</td>\n      <td>80203.0</td>\n      <td>49954</td>\n      <td>739013.0</td>\n      <td>28819</td>\n      <td>3332</td>\n      <td>2837</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "giant_grouped_df.sort_values(['Confirmed'], ascending=False, inplace=True)\n",
    "giant_grouped_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "time = datetime.now().strftime(\"%H:%M\")\n",
    "giant_grouped_df.to_csv(f\"output/COVID9-cleaned_{date}_{time}.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit381pyenv80f8106dbcde49aa8072c8f85b1ed604",
   "display_name": "Python 3.8.1 64-bit ('3.8.1': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}